<!DOCTYPE HTML>
<html lang="zh-tw">
<head>
    <meta charset="utf-8" />
    <meta http-equiv="content-language" content="zh-tw" />
    <meta name="robots" content="noodp, nofollow" />
    <meta name="description" content="醬找專利是一個將專利資訊視覺化的網站，把專利檢索的結果以儀表板的方式呈現。" />
    <meta name="keywords" content="專利 醬找專利 專利檢索 儀表板 大數據 雲端 專利地圖 專利分析 patent dashboard big data cloud patent map patent analysis patent search" />

    <!-- 辨識醬找專利 -->
    <!-- Organization Schema -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Organization",
      "name": "醬找專利",
      "url": "https://patenthunterjohn.com",
      "logo": "https://patenthunterjohn.com/logo.jpg",
      "description": "醬找專利是一個將專利資訊視覺化的網站，把專利檢索的結果以儀表板的方式呈現。",
      "sameAs": []
    }
    </script>

    <title>醬找專利 　|　專利儀表板</title>

    <!-- Scripts -->
    <script src="js/jquery.min.js"></script>
    <script src="js/jquery.dropotron.min.js"></script>
    <script src="js/jquery.scrollgress.min.js"></script>
    <script src="js/jquery.scrolly.min.js"></script>
    <script src="js/jquery.slidertron.min.js"></script>
    <script src="js/skel.min.js"></script>
    <script src="js/skel-layers.min.js"></script>
    <script src="js/init.js"></script>

    <!-- Stylesheets -->
    <noscript>
        <link rel="stylesheet" href="css/skel.css" />
        <link rel="stylesheet" href="css/style.css" />
        <link rel="stylesheet" href="css/style-xlarge.css" />
    </noscript>

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="css/ie/v9.css" />
    <![endif]-->
    <!--[if lte IE 8]>
        <script src="css/ie/html5shiv.js"></script>
        <link rel="stylesheet" href="css/ie/v8.css" />
    <![endif]-->

    <!-- Google Analytics v1 -->
    <script>
        (function(i,s,o,g,r,a,m){
            i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)
            },i[r].l=1*new Date();
            a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];
            a.async=1;a.src=g;
            m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-XXXXX-Y', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- Google Analytics v2 -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-212822931-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-212822931-1');
    </script>
	</head>

<body class="landing">

    <!-- 辨識醬找專利2 -->
    <!-- H1 標題 
    <section id="home-title">
      <h1 style="text-align: center;">醬找專利</h1>
    </section>-->

    <!-- Header -->
    <header id="header" class="alt skel-layers-fixed">
        <nav id="nav">
            <ul>
                <li><a href="index.html">首頁</a></li>
                <li>主題導覽
                	<ul>
						<li><a href="#dash-03">【儀表板】臺灣專利2025年動態追蹤</a></li>
						<li><a href="#dash-02">【儀表板】抬頭顯示器（HUD）</a></li>
						<li><a href="#dash-01">【儀表板】Meta專利透視元宇宙技術</a></li>

			
					</ul>
				</li>
                <li><a href="publications.html">個人著作</a></li>
                <li><a href="about.html">關於我們</a></li>
                <li><a href="privacy-policy.html">隱私政策</a></li>
                
                <!-- 可加上更多導覽項目 -->
            </ul>
        </nav>
    </header>

    <!-- Banner -->
    <section id="banner">
        <div class="inner">
            <h2>醬找專利</h2>
            <p>專利檢索 | 專利地圖 | 大數據 | 儀表板 | 雲端 | 開放平台</p>

            <br><br><br><br>

            <ul class="actions">
                <li><a href="#logo" class="button big scrolly">開始探索</a></li>
            </ul>
            <p>網站更新日期：2025/5/16</p>
        </div>
    </section>

    <!-- Logo -->
    <section id="logo">
        <br><br>
        <div style="width: 150px;">
            <img src="logo.jpg" height="50" width="150" alt="醬找專利 Logo" />
        </div>
    </section>

    <!-- One: 主要內容 -->
    <section id="one" class="wrapper style1" style="background-color: white;">

<!-- 儀表板03 -->
<details>
  <summary id="dash-03" style="margin-left: 30px; cursor: pointer;">
    【儀表板】臺灣專利 2025 年動態追蹤 | 更新日: 2025/5/10
  </summary>
 <div class="box post" style="width: 80%; margin: 0 auto; line-height: 1.8;">
<p align="left">
      ✅ 本儀表板 <strong>即時更新2025年</strong> 公開的臺灣專利。<br>
      ✅ 請善用專利資料表格中的「filter data...」欄位，輸入關鍵字並按 Enter 鍵，即可針對各欄位進行資料篩選。
例如，在「公開/公告日」欄位輸入「202501」，並在「專利名稱」欄位輸入「眼鏡」，即可篩選出 2025 年 1 月公開的眼鏡相關專利。<br> 
      ✅ 使用下方的篩選條件，可進一步縮小專利資料的範圍。每個篩選項目內的按鈕採「OR」邏輯，項目之間則以「AND」邏輯結合。
      例如：在「公開種類」中點選「B」與「U」，並在「近5申請年」中選擇「2023」，其對應的檢索式為：(公開種類 = B OR U) AND (申請年 = 2023)。
      這表示篩選出 2023 年申請，且已公告核准的專利。<br>
      ✅ 儀表板載入時間約為 1 至 3 分鐘，敬請耐心等候。如網頁閒置過久，請重新整理頁面以恢復儀表板功能。
    </p>
	</div>
  <!-- 內嵌 Dash App iframe -->
  <div class="box post" style="width: 100%; margin: 0 auto;">
    <iframe
      src="https://dash05.onrender.com" style="width: 1660px; height: 812px"> <!-- Dash App 的網址，請替換為你自己的 URL -->
    </iframe>
  </div>
</details>


<!-- 儀表板02 -->
<details>
  <summary id="dash-02" style="margin-left: 30px; cursor: pointer;">
    【儀表板】抬頭顯示器(HUD) | 更新日: 2025/5/9
  </summary>
 <div class="box post" style="width: 80%; margin: 0 auto; line-height: 1.8;">
<p align="left">
      ✅ 本儀表板涵蓋截至 <strong>2025/04/30</strong> 前公開的美國專利，涉及 IPC 分類 <strong>G02B 27/01</strong> 的抬頭顯示器（HUD）。<br>
      ✅ 請使用下方篩選條件，即時動態更新專利資料表格。<br>
      ✅ 儀表板載入時間約為 1 至 3 分鐘，敬請耐心等候。如網頁閒置過久，請重新整理頁面以恢復儀表板功能。
    </p>
	</div>
  <!-- 內嵌 Dash App iframe -->
  <div class="box post" style="width: 100%; margin: 0 auto;">
    <iframe
      src="https://dash04.onrender.com" style="width: 1660px; height: 812px"> <!-- Dash App 的網址，請替換為你自己的 URL -->
    </iframe>
  </div>
</details>

<!-- 圖層12 -->  
<div style="display: flex; align-items: center; padding-left: 25px;">
  <p style="margin: 0;">
    📄<a href="\hud\nvidia_hud_ar_technology_2019_2025.html" style="text-decoration: none; color: inherit;">
      輝達（NVIDIA）抬頭顯示器技術 ：從基礎模組優化，拓展至智能互聯與AR穿戴雙重布局（2015–2025） | 更新日: 2025/5/16
    </a>
  </p>
</div>

<!-- 圖層11 -->      
<details>
  <summary id="hud-05" style="margin-left: 30px; cursor: pointer;">        
  抬頭顯示器(HUD) — GREE Holdings, Inc.公司 — 從手機遊戲到虛擬互動平台的多元化布局 | 更新日: 2025/5/15 
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">抬頭顯示器(HUD) — GREE Holdings, Inc.公司 — 從手機遊戲到虛擬互動平台的多元化布局</h3>   
 
 <p align="left">
 
✅ GREE Holdings, Inc.（グリーホールディングス株式会社）是一家總部位於日本東京六本木的科技與娛樂控股公司，成立於2004年12月7日，創辦人為田中良和（Yoshikazu Tanaka） 。該公司原以社交網路服務（SNS）起家，後來轉型為多元化的數位娛樂與科技集團，旗下擁有多個子公司與品牌，涵蓋手機遊戲、虛擬實境（Metaverse）、虛擬YouTuber（VTuber）以及數位轉型（DX）等領域。（資料來源：<a href="https://en.wikipedia.org/wiki/Gree_%28Japanese_company%29?" target="_blank">維基百科</a>）<br>
✅ GREE Holdings 的 Metaverse 業務主要透過平台「REALITY」來實現，該平台讓用戶能夠利用手機創建原創虛擬角色（Avatar），進行直播、互動與遊戲等活動 。此外，REALITY Studios 作為 VTuber 經紀公司，管理並製作多位虛擬主播，並透過音樂、直播、商品等多元方式提供娛樂內容 。（資料來源：<a href="https://hd.gree.net/jp/en/business/metaverse.html" target="_blank">GREE公司</a>）<br>
✅ GREE與Square Enix曾共同申請專利（US10802279B2、US10286303B2）。此外，由GREE與Square Enix合作開發的虛擬實境角色指揮角色扮演遊戲《Kai-ri-Sei Million Arthur VR》（乖離性百萬亞瑟王 VR）於2017年5月25日首次在日本發行，並於同年10月12日進軍美國、英國、加拿大和澳洲市場，支援HTC Vive平台。（資料來源：<a href="https://lpcomment.com/2016/09/01/kai-ri-sei-million-arthur-vr-htc-vive-ver/" target="_blank">LPComment 科技生活雜談</a>）<br>

</p> 

 
 
<table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開/公告日</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">申請人</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240418</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20240127558A1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過電路系統控制虛擬空間影像的顯示方式，根據第一使用者的姿態將虛擬空間的第一影像輸出至第一顯示裝置，同時允許第二使用者透過操作來指定其顯示範圍，並將對應的第二影像輸出至第二顯示裝置。當第二使用者對該第二影像中可視辨識的物件進行選取操作時，系統會根據該操作改變第一影像中該物件的顯示模式，使第一使用者所見的影像發生變化，以實現跨使用者間的互動與視覺資訊共享。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240206</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11893697B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是利用儲存於非暫態性電腦可讀媒介中的可執行指令，透過系統電路的執行，達成多使用者於虛擬空間中的互動影像控制。系統會根據第一使用者的姿態將虛擬空間的第一影像輸出至其所配戴的第一顯示器，並同步將第二影像輸出至第二使用者的顯示器。當第二使用者針對其顯示畫面進行輸入操作時，該操作會僅改變虛擬空間中某一第一物件的移動狀態，而這個變化將即時反映於第一使用者所見的第一影像中。進一步地，系統也會偵測第一使用者對反映該物件移動後的第一影像所進行的操作。值得注意的是，該第一物件僅會在其位於第一與第二影像顯示範圍的重疊區域，且已經由第二使用者操作改變移動狀態後，才會在第一影像中被可視化地顯示，從而實現基於使用者注意範圍與互動行為的動態影像呈現。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231226</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11854155B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過儲存於非暫態性電腦可讀媒介中的資料處理程式，使控制器在顯示裝置上呈現虛擬空間影像時，具備特定的顯示處理功能。當從外部輸入第一外部資訊時，控制器會作為第一顯示處理單元運作，透過存取記憶體中關於虛擬空間內物件的資訊，判別並指定一個第一指定物件，該物件為虛擬空間中以特定位置呈現的資訊處理裝置。系統會將該第一外部資訊以疊加方式顯示於該指定物件的特定範圍上；若同時輸入多筆第一外部資訊，則會依據各資訊的類型來判定優先順序，並僅將最高優先級的資訊顯示於該虛擬物件上。此機制使得虛擬空間中的資訊呈現具備即時性與關聯性，強化使用者對重點資訊的辨識與互動效率。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231212</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11839811B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過儲存於非暫態性電腦可讀媒介中的遊戲處理指令，當由系統電路執行時，可實現虛擬空間中與玩家實際位置互動的顯示控制。系統會控制第一玩家所配戴的顯示裝置，以對應其在虛擬空間中的第一虛擬位置來顯示該空間，並將該虛擬位置的初始點設為預先設定的位置。接著，系統根據第一玩家在現實空間中的動作設定一個第一可移動區域，並透過第一感測器的輸出判斷玩家的實際位置，使虛擬位置能隨玩家的實體移動而更新。當判定該虛擬位置與可移動區域的邊界距離小於或等於預設距離時，系統會於顯示裝置中呈現一個區域指示標記，用以標示可移動區域範圍。只要該虛擬位置接近或已超出該範圍，此區域指示標記將持續顯示，以協助玩家即時掌握自身在虛擬空間中的活動界線，提升沉浸式體驗的安全性與互動性。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231026</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20230338832A1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過系統內部的電路裝置，提供多位玩家共享的虛擬空間互動體驗。系統會先將虛擬空間的影像及與第一玩家對應的虛擬角色（第一虛擬化身）輸出至該玩家所使用的第一終端裝置。接著，在預定的時機點下，系統會擷取至少包含第一虛擬化身在內的虛擬畫面，並產生包含該擷取影像的影像資訊。此影像資訊的全部或部分會被輸出至非屬於第一玩家的第二終端裝置，讓其他玩家也能看到與第一玩家相關的虛擬畫面，藉此實現跨終端之間的資訊分享與角色互動，提升多玩家間的沉浸感與同步感。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240418</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20240127558A1</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過電路系統控制虛擬空間影像的顯示方式，根據第一使用者的姿態將虛擬空間的第一影像輸出至第一顯示裝置，同時允許第二使用者透過操作來指定其顯示範圍，並將對應的第二影像輸出至第二顯示裝置。當第二使用者對該第二影像中可視辨識的物件進行選取操作時，系統會根據該操作改變第一影像中該物件的顯示模式，使第一使用者所見的影像發生變化，以實現跨使用者間的互動與視覺資訊共享。</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240206</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11893697B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是利用儲存於非暫態性電腦可讀媒介中的可執行指令，透過系統電路的執行，達成多使用者於虛擬空間中的互動影像控制。系統會根據第一使用者的姿態將虛擬空間的第一影像輸出至其所配戴的第一顯示器，並同步將第二影像輸出至第二使用者的顯示器。當第二使用者針對其顯示畫面進行輸入操作時，該操作會僅改變虛擬空間中某一第一物件的移動狀態，而這個變化將即時反映於第一使用者所見的第一影像中。進一步地，系統也會偵測第一使用者對反映該物件移動後的第一影像所進行的操作。值得注意的是，該第一物件僅會在其位於第一與第二影像顯示範圍的重疊區域，且已經由第二使用者操作改變移動狀態後，才會在第一影像中被可視化地顯示，從而實現基於使用者注意範圍與互動行為的動態影像呈現。</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231226</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11854155B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過儲存於非暫態性電腦可讀媒介中的資料處理程式，使控制器在顯示裝置上呈現虛擬空間影像時，具備特定的顯示處理功能。當從外部輸入第一外部資訊時，控制器會作為第一顯示處理單元運作，透過存取記憶體中關於虛擬空間內物件的資訊，判別並指定一個第一指定物件，該物件為虛擬空間中以特定位置呈現的資訊處理裝置。系統會將該第一外部資訊以疊加方式顯示於該指定物件的特定範圍上；若同時輸入多筆第一外部資訊，則會依據各資訊的類型來判定優先順序，並僅將最高優先級的資訊顯示於該虛擬物件上。此機制使得虛擬空間中的資訊呈現具備即時性與關聯性，強化使用者對重點資訊的辨識與互動效率。</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231212</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11839811B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過儲存於非暫態性電腦可讀媒介中的遊戲處理指令，當由系統電路執行時，可實現虛擬空間中與玩家實際位置互動的顯示控制。系統會控制第一玩家所配戴的顯示裝置，以對應其在虛擬空間中的第一虛擬位置來顯示該空間，並將該虛擬位置的初始點設為預先設定的位置。接著，系統根據第一玩家在現實空間中的動作設定一個第一可移動區域，並透過第一感測器的輸出判斷玩家的實際位置，使虛擬位置能隨玩家的實體移動而更新。當判定該虛擬位置與可移動區域的邊界距離小於或等於預設距離時，系統會於顯示裝置中呈現一個區域指示標記，用以標示可移動區域範圍。只要該虛擬位置接近或已超出該範圍，此區域指示標記將持續顯示，以協助玩家即時掌握自身在虛擬空間中的活動界線，提升沉浸式體驗的安全性與互動性。</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231026</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20230338832A1</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">本技術之原理是透過系統內部的電路裝置，提供多位玩家共享的虛擬空間互動體驗。系統會先將虛擬空間的影像及與第一玩家對應的虛擬角色（第一虛擬化身）輸出至該玩家所使用的第一終端裝置。接著，在預定的時機點下，系統會擷取至少包含第一虛擬化身在內的虛擬畫面，並產生包含該擷取影像的影像資訊。此影像資訊的全部或部分會被輸出至非屬於第一玩家的第二終端裝置，讓其他玩家也能看到與第一玩家相關的虛擬畫面，藉此實現跨終端之間的資訊分享與角色互動，提升多玩家間的沉浸感與同步感。</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20210921</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11127224B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">
    本技術之原理是透過儲存於非暫態性電腦可讀媒介中的資料處理程式，使控制器在玩家頭戴式顯示裝置上顯示虛擬空間影像時，具備兩種顯示處理功能。第一顯示處理器會在接收到第一外部資訊時，根據該資訊的內容及記憶體中虛擬物件的資訊，指定虛擬空間中已有的特定物件作為顯示對象，並將第一外部資訊以疊加方式呈現在該物件上；該指定物件會依外部資訊內容動態調整。第二顯示處理器則在接收到第二外部資訊時，能將包含實體空間影像的第二外部資訊與虛擬空間影像一併顯示。第一顯示處理器會判斷當前虛擬場景是否處於預定時機，若不在該時機且第一外部資訊屬於較低優先權，則不予顯示；若在預定時機或第一外部資訊具有較高優先權，則強制顯示該資訊，確保重要資訊能於適當時間及情況下清楚呈現，提升使用者的資訊掌握與體驗品質。
  </td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>

</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20201013</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10802279B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">SQUARE ENIX CO., LTD.;GREE, Inc.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">
    本技術之原理是透過包含頭戴式顯示裝置的顯示系統，利用虛擬攝影機處理器根據顯示裝置的方向來指定虛擬攝影機的視軸，並根據顯示裝置的姿態資訊判斷玩家的視線方向。當虛擬遊戲角色被判定其設定的多個預定區域（以多個球體代表角色不同身體部位）與玩家視線相交時，系統會擷取該虛擬角色的遊戲狀態資訊（包括角色的狀態或屬性），並將該資訊顯示在角色附近。該系統亦能根據與顯示裝置分離的控制器裝置所接收的輸入，產生用於顯示的影像，藉此提升玩家在虛擬空間中的互動體驗與資訊可視化，並使得玩家能更直覺地了解虛擬角色的狀態與反應。
  </td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20200630</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10695666B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">
    本技術之原理是透過儲存於非暫態性電腦可讀媒介中的指令，使系統能分別控制第一及第二玩家所配戴的頭戴式顯示器，將虛擬空間影像與對應的第一及第二虛擬位置顯示於各自裝置上。系統會將兩虛擬位置的初始位置設定為預先指定的位置，且該初始虛擬距離與玩家在現實空間中配戴裝置的實際距離不同。透過第一與第二感測器分別偵測兩玩家在現實空間中的位置，並根據此資訊移動對應的虛擬位置。當虛擬位置間的距離符合預定條件時，系統即在遊戲中產生特殊效果，藉此增強玩家間的互動感與遊戲體驗。
  </td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20200528</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20200166755A1</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">GREE, INC.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">
    本技術之原理是透過一種頭戴式顯示器設計，其包含一個可依照使用者頭部大小調整長度的固定部件，以及一個固定於該固定部件上的顯示裝置，該顯示裝置的顯示面在佩戴時朝下；同時配備一個反射元件，其反射面朝向顯示裝置的顯示面，能將顯示影像反射至使用者的眼球；此外，設有遮蔽部份，用以遮蔽包含顯示裝置與反射元件的空間，防止外界光線干擾，確保使用者在使用過程中能獲得清晰且穩定的視覺體驗。
  </td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
<tr>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20190514</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10286303B2</td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">SQUARE ENIX CO., LTD.;GREE, Inc.</td>
  <td style="border: 1px solid #ccc; padding: 10px;">
    本技術之原理是利用一款配備頭戴式顯示器與控制器的遊戲系統，透過第一感測器偵測顯示器的方向及位置，第二感測器偵測控制器的方向，顯示器根據自身方向與位置顯示虛擬空間遊戲狀態及多項第一選項。控制器則依據顯示器與控制器方向的相對關係，選擇至少一項第一選項，並在選擇後移動以跟隨控制器的動作，隨後再依同樣的相對關係選擇至少一項第二選項，顯示器同時顯示多項第二選項。遊戲處理器則依據所選的第一及第二選項推進遊戲進程，藉此提升玩家操作的直覺性與互動性。
  </td>
  <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
</tr>
    </tbody>
  </table>
</div>
</details>


<!-- 圖層10 -->     
<details>
  <summary id="hud-04" style="margin-left: 30px; cursor: pointer;">       
  抬頭顯示器(HUD) — 車用抬頭顯示器（高引用次數） | 更新日: 2025/5/14
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">抬頭顯示器(HUD) — 車用抬頭顯示器（高引用次數） </h3>   
 
<table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">申請人</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
		<tr>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">1585</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10272839B2</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">MAGNA ELECTRONICS INC.</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用設置於車室內的攝影鏡頭與影像顯示螢幕，結合可見光與近紅外線照明裝置，以即時監控後座乘客狀況並顯示於駕駛人可視的抬頭顯示器（HUD）上。該攝影機內建CMOS影像感測器與鏡頭，安裝於車頂的頂燈或上控台位置，具備涵蓋後座區域的視野範圍。為確保在不同光源條件下均能清晰拍攝，系統搭配可見光LED與近紅外線LED作為照明來源，分別提供日間與夜間的輔助光源。當攝影機拍攝後座影像時，影像資料會即時傳送至顯示螢幕，使駕駛可透過HUD裝置掌握後座乘客的即時動態，提升行車安全與乘車管理效率。</td>
    <td style="border: 1px solid #ccc; padding: 10px;"></td>
  </tr>
  <tr>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">1500</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10914950B2</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">DigiLens Inc.</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用一種波導顯示裝置，該裝置採用夾在兩層透明基板之間的全像高分子分散液晶（HPDLC）材料層，並在其中設置輸入光柵、第一與第二折射光柵及輸出光柵，以實現光的導入、傳遞、擴展與輸出。當影像訊號從輸入影像節點進入後，輸入光柵將光線耦合進波導中，透過全內反射傳輸至兩個折射光柵，再引導至輸出光柵，最終將影像顯示於使用者眼前。為了擴大可視範圍，輸入與輸出光柵中至少一者為多工光柵，可同時支援多條波導路徑，分別對應視野中的不同區域，進行光束展開與輸出，使抬頭顯示器（HUD）能提供更廣的視野與更清晰的影像呈現，大幅提升駕駛資訊的可讀性與即時性。</td>
    <td style="border: 1px solid #ccc; padding: 10px;"></td>
  </tr>
  <tr>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">722</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US9694752B2</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">Gentex Corporation</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過一種具備可調整機構的車用後視鏡結構，將反射鏡基板以可動方式設置於鏡殼中，並利用驅動輪與安裝板之間的互動來實現鏡面角度的調整與定位。該系統包含一安裝板，其一端可旋轉地固定於鏡殼內部，另一端設有插槽與具凹槽的曲面；驅動輪則設置於與安裝板相對的鏡殼端，內部設有可轉動的凸銷與凸輪。當驅動輪旋轉時，凸銷進入插槽，帶動安裝板旋轉至不同角度，並藉由凸輪與凹槽表面之接觸，形成穩定的定位結構，有效防止鏡面於行車過程中因震動而偏移。此後視鏡結構可進一步整合於抬頭顯示器（HUD）系統中，使鏡面調整更精準，進而提升影像投影與反射的一致性與穩定性，增強駕駛視覺資訊的辨識效果。</td>
    <td style="border: 1px solid #ccc; padding: 10px;"></td>
  </tr>
  <tr>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">585</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11767250B2</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">CORNING INCORPORATED</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用真空成形法製作抬頭顯示器（HUD）系統所需之三維曲面鏡，透過將具備特定形狀的玻璃基材預成品放置於具凹面結構的模具上，並在其第二主表面與模具之間施加真空，使該表面緊貼模具凹面形成所需的三維曲率。模具周圍設有延伸至預成品高度的縱向壁，協助定位並支撐玻璃在變形過程中的穩定性，同時橫向邊緣因預先設計為與模具曲率對應的弧形，可在真空吸附下保持一致接觸，確保成品邊緣平滑連續。該方法不需於變形後再進行裁切，避免破壞鏡面結構或影響光學品質，最終可製得符合HUD系統高精度需求的三維鏡面元件，提升影像投影的準確性與視覺清晰度。</td>
    <td style="border: 1px solid #ccc; padding: 10px;"></td>
  </tr>
  <tr>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">553</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US9679367B1</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">Wald, Daniel S., et al.</td>
    <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過結合感測器陣列、光波導結構與動態調光技術，實現可因應駕駛艙內強光環境而自動調節的抬頭顯示器（HUD）系統。該系統包含一組波導式合成器，可同時顯示外部視野與來自影像來源的資訊影像，並利用波導的全內反射原理，將影像從輸入口傳輸至輸出口，再投影至駕駛人視野中的虛擬位置（eye box）。當感測器陣列偵測到駕駛艙內有過強的背景光干擾時，處理電路即依據感測資料判斷干擾光的位置與形狀，並產生控制訊號，啟動合成器內對應位置的可選擇性不透明區域（動態漸層遮光區），藉此選擇性地降低或阻擋干擾光的穿透，確保駕駛人能清晰辨識抬頭顯示的影像內容，提升行車安全與顯示品質。</td>
    <td style="border: 1px solid #ccc; padding: 10px;"></td>
  </tr>
  <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">441</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10427604B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">MAGNA ELECTRONICS INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用車輛視覺系統整合多個鏡面與攝影機，並透過內建的影像顯示技術提供駕駛更清晰、即時的後方視野。該系統包含安裝於車輛左右兩側外後視鏡的反射鏡與攝影機，當駕駛調整後視鏡角度時，對應的攝影機會補充盲點區域的影像，並將影像資料傳送至內部後視鏡的顯示螢幕。內部後視鏡具備一個可顯示駕駛側與乘客側影像資料的顯示區，根據影像資料來自駕駛側或乘客側的影像來源，分別顯示在顯示螢幕的駕駛側或乘客側區域。此技術結合了電致變色反射鏡和隱藏式顯示螢幕設計，使得當顯示螢幕未顯示影像時，後視鏡仍可保持原本的反射功能；而當顯示影像時，駕駛可直接在後視鏡中看到來自攝影機的即時畫面，提供更廣的視野範圍與更高的行車安全性，特別是對於盲點區域的有效監控。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">440</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10059265B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">MAGNA ELECTRONICS INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用車輛視覺系統整合駕駛側與乘客側的外後視鏡攝影機與內部後視鏡的顯示功能，為駕駛提供更全面的視覺資訊。此系統包含安裝於車輛左右兩側的外後視鏡，每個外後視鏡配備一個反射鏡與攝影機，並能捕捉來自駕駛側與乘客側的後方影像資料。這些影像資料會傳輸到內部後視鏡的顯示螢幕，該螢幕分為駕駛側與乘客側顯示區域，分別顯示來自兩側攝影機的影像。內部後視鏡的顯示區域設計為，駕駛側顯示區較靠近駕駛側外後視鏡，乘客側顯示區則較靠近乘客側外後視鏡。這樣，駕駛人能夠在駕駛位置輕鬆查看來自兩側的影像，特別是當調整後視鏡角度時，系統會自動補充盲點區域的影像，提升行車安全與視覺效果。此系統讓駕駛人能更精確地掌握周遭環境，確保更高的行車安全性。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">439</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US9843777B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">MAGNA ELECTRONICS INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用車輛的艙內監控系統，透過安裝在車頂的攝影機組與照明設備，對車內後座區域進行監控。當照明設備啟動時，它會照亮後座區域，使得攝影機能夠捕捉到清晰的影像資料。這些影像資料會被傳送至車內的顯示螢幕，讓駕駛人在駕駛時可以清楚地看到後座區域的狀況。此系統的設計有助於提升駕駛的安全性，特別是在需要注意車內狀況時，例如確保後座乘客安全或觀察車內環境的變化。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">438</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US9637053B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">MAGNA ELECTRONICS INC.</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過車輛內部設置的附件系統，將一個包含前向攝影機的模組安裝於車輛的擋風玻璃上，並利用特殊的附著元件將其牢固固定。該前向攝影機擁有超過60 dB的動態範圍，可穿透擋風玻璃捕捉影像，並作為駕駛輔助系統的一部分，提供例如自動頭燈控制系統或碰撞避免系統的影像數據。該模組可隨時拆卸進行維護或更換，而不會影響後視鏡的安裝或拆卸，並且擋風玻璃上的光吸收層可有效隱藏附著元件，避免外部視覺上的干擾，提升車輛整體的美觀與功能性。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">291</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11119315B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">MAXELL, LTD., et al.</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過一個資訊顯示裝置，將虛擬影像投射於車輛的擋風玻璃上，並根據影像資訊顯示不同的影像位置。該裝置包含一個平面顯示器，根據視頻影像資訊顯示影像，並結合虛擬影像光學系統，利用多個光學元件來反射顯示器發出的光至擋風玻璃，形成不同距離的虛擬影像。光學系統中包括一個凹面鏡，位於顯示器與擋風玻璃之間，並且每個光學元件依照所需的位置來調整影像的焦距和放大倍率。這些虛擬影像會在擋風玻璃的不同位置上重疊顯示，例如背景影像位於上方，前景影像位於下方，且各虛擬影像的大小呈現出背景影像比前景影像大（V3 &gt; V1）的關係。這樣的設計能夠使駕駛者在駕駛時，同時觀看來自現實世界和虛擬影像的資訊，進而提高安全性與駕駛體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
</tbody>
  </table>
</div>
</details>


<!-- 圖層09 -->    
<details>
  <summary id="hud-03" style="margin-left: 30px; cursor: pointer;">      
  抬頭顯示器(HUD) — Magic Leap公司（高引用次數） — 利用 AR 技術提供沉浸式的眼疾診斷體驗 | 更新日: 2025/5/13      
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Magic Leap公司（高引用次數） — 利用 AR 技術提供沉浸式的眼疾診斷體驗</h3>   
 <p align="left">
 
✅ Magic Leap 是一家成立於 2010 年的美國擴增實境公司，曾獲得高達 14 億美元的融資，投資者包括 Google 和阿里巴巴集團（資料來源：<a href="https://zh.wikipedia.org/zh-tw/Magic_Leap" target="_blank">維基百科</a>）。<br>
✅ 根據統計，Magic Leap 擁有 1,052 件與抬頭顯示器（HUD）相關的專利，數量居冠。其中，有 93 件專利與診斷、外科或鑑定用途有關（IPC/CPC 分類為 A61B）。下表整理出其中引用次數最多的前十件專利。<br>
✅ Magic Leap公司的「Magic Leap 2」產品將增強現實技術與醫療保健相結合，並在眼疾診斷領域帶來重大突破。它提供沉浸式體驗，讓醫療專業人員能夠準確分析眼部狀況，實現快速診斷。透過遠程會診，來自全球的專家能夠即時合作，提升治療效果。這項創新技術將徹底改變眼疾診斷方式，促進早期檢測與干預，最終改善患者的治療效果與生活質量。（資料來源：<a href="https://blogs.expandreality.io/magic-leap-2-and-healthcare" target="_blank">Expand Reality網站，作者Simon Hunt</a>）
</p> 
<table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">757</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11747627B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230905</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過頭戴式顯示系統中的光源發出包含影像資訊的光，並利用光波導（waveguide）將該光導入系統，再藉由耦合光學元件將光導向使用者眼睛，形成覆蓋視野周邊多個位置的虛擬影像。該光波導不僅能傳遞環境光，還能引導並輸出來自光源的影像光，使虛擬影像與真實環境疊合。系統中配置的眼動追蹤相機可拍攝使用者眼睛以判斷其視線方向，搭配使用者介面可接收其反應輸入，藉此評估其在不同視野位置對影像的辨識能力。此外，系統採用多層堆疊的光波導設計，每層波導具備不同的出光發散角度，藉此實現多焦段或更自然的影像深度效果，提升虛實整合的顯示品質與視覺舒適度。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">737</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11474359B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20221018</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是運用可穿戴式擴增實境系統，藉由光源發出帶有影像資訊的光，透過一組堆疊式光波導將此光耦合並導向使用者眼睛，同時保留環境光的穿透，使虛擬影像與現實視野融合。各層光波導具備不同的波前發散量，對應至不同的景深平面，進而呈現具立體感與深度層次的虛擬內容。系統亦包含使用者介面，可接收配戴者的操作輸入，並可調用其視野缺損資料，當偵測到使用者環境中有事件或狀況發生於其視覺缺陷區域時，系統會主動發出提示，協助使用者察覺潛在風險或重要資訊，增進其安全與互動體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">693</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11256096B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220222</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用可穿戴式擴增實境顯示裝置，讓外部環境光能穿透顯示器進入配戴者眼中，同時透過內建光學元件投射虛擬影像至眼內，使虛實畫面整合。該裝置特別設計能針對影像的不同色彩元件輸出具不同波前發散量的光，其中第一色彩元件對應至第一景深平面，第二色彩元件則對應至不同的第二景深平面，藉此補償使用者眼睛因色差（縱向色差）所造成的視覺偏差，提升虛擬影像在多色彩呈現下的對焦準確性與觀看舒適度。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">678</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10983351B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20210420</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過可穿戴式擴增實境系統，使用具備光源與多層光波導堆疊的顯示裝置，將帶有影像資訊的光導入配戴者眼中，同時保留環境光進入眼睛，使虛擬資訊與真實世界重疊呈現。各層光波導具備不同的波前發散量，可對應至不同景深平面，形成具有深度感的立體影像，以提升視覺真實性與沉浸感。系統同時搭配使用者介面，能接收配戴者操作輸入，並讀取其視野缺損資料，當偵測到使用者周遭存在因視覺缺陷而無法察覺的潛在危險時，系統會即時發出警示，協助使用者避開風險，提升使用安全與互動效能。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">678</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10969588B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20210406</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過可穿戴式擴增實境顯示系統，利用具備光源的顯示裝置將含有影像資訊的光導入配戴者眼中，讓虛擬影像與真實環境光共同進入視覺系統，實現虛實整合的顯示效果。該系統包含使用者介面，可接收配戴者的輸入操作，並能存取其對比敏感度相關資料，以判斷其視覺在辨識低對比環境中的能力。當系統偵測到配戴者因對比敏感度不足而無法察覺的潛在危險情況時，會即時發出提示或警示，協助其辨識周遭風險，有效提升其使用安全性與情境感知能力。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">530</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11737832B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230829</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用一套具備真實物體偵測裝置的顯示系統，透過感測器偵測現實空間中多個可移動物件的位置，並由處理器執行儲存在電腦可讀媒介上的指令，將偵測到的空間與物件資訊產生為數位地圖，形成可反映實體環境狀態的虛擬表示。系統中的地圖儲存模組會將該數位地圖儲存於資料儲存裝置中，而導引模組則會根據此地圖執行虛擬或實體物件的導引功能，特別是用於房間配置情境。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">529</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11756335B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230912</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用光源產生包含兩種波長範圍的光，並透過光調變器將第一波長範圍的光轉換為影像光束，同時將第二波長範圍的光轉換為探測光束。這兩種光束會經由入射耦合元件分別導入第一與第二光波導中，其中影像光束會進入兩個光波導並輸出至使用者眼睛，以提供視覺顯示效果；而探測光束則經由第一光波導的出射耦合元件擴展後，同樣導向眼睛，用於偵測眼球反射光訊號。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">413</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10775628B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20200915</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過一套可穿戴式眼科抬頭顯示系統，結合頭戴式顯示裝置、視線感測器與自適應光學元件，以輔助老花眼使用者的視覺調節能力。系統中的顯示裝置可將光源產生的影像光導入至少一眼，形成虛擬影像，同時具備感測器以判斷雙眼注視方向，進而計算出視線匯聚點的位置。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">353</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11347960B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220531</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用一組具備多波長輸出能力的光源，同時產生第一波長範圍的光與第二波長範圍的光，並經由光調變器分別轉換為影像光束與探測光束。影像光束與探測光束分別透過第一與第二光波導的入射耦合區導入系統，再經由各自的出射耦合區將影像光輸出至使用者眼中供觀看，同時將探測光輸出至眼睛表面以偵測其反射訊號。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">341</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11029147B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20210608</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過一套穿戴式顯示裝置，協助醫師在手術過程中進行更精確的操作。該顯示裝置能接收與患者手術相關的數據，並追蹤醫師頭部的姿態，將患者的三維解剖模型虛擬呈現在顯示裝置中。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>



<!-- 圖層08 -->    
<details>
  <summary id="hud-02" style="margin-left: 30px; cursor: pointer;">      
  抬頭顯示器(HUD) — Apple公司（高發明人數） — Apple Vision Pro 的專利布局 | 更新日: 2025/5/12      
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">抬頭顯示器(HUD) — Apple公司（高發明人數） — Apple Vision Pro 的專利布局</h3>   
 <p align="left">
  ✅ Apple公司的HUD專利中，發明人數20人以上的專利包含以下4件。從專利圖（每件均有593張圖）來看，很像是產品「Apple Vision Pro」的專利布局。<br>
  ✅ 「Apple Vision Pro」的產品介紹請參閱維基百科：<a href="https://en.wikipedia.org/wiki/Apple_Vision_Pro" target="_blank">https://en.wikipedia.org/wiki/Apple_Vision_Pro</a><br>
    ✅ 值得注意的是，「Apple Vision Pro」產品尚有其它專利布局，本文僅以發明人數達20人以上之專利作為說明範例。
</p> 
<table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">發明人數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">27</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20240385453A1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241121</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過將光學模組安裝於裝置外殼中，並結合可佩戴於頭部的結構設計，如臉部接觸界面、固定帶與繫帶，讓使用者在佩戴時可於視野中直接顯示資訊。光學模組會將影像或數據投影至使用者眼前，通常利用半透明鏡片或波導元件，使影像與實際視野重疊，達成即時資訊疊加的抬頭顯示效果。此外，處理器被配置於固定帶內部，用以處理來自感測器或其他輸入裝置的數據，並控制影像內容，使整體系統能同步運作並提供互動功能。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">22</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20240385454A1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241121</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過將光學模組、內部顯示器與感測器整合於可佩戴於頭部的裝置中，藉由外部顯示器與外部感測器接收環境資訊，並經由處理後投影至內部顯示器，使使用者可在視線範圍內即時獲得外部特徵的視覺呈現。同時，內部感測器可偵測使用者的生理或行為特徵，並將相關資訊透過外部顯示器對外顯示，實現內外資訊互通。此設計結合固定繫帶確保裝置穩固配戴，使抬頭顯示器能即時呈現與環境或使用者狀態相關的資訊，提升使用者互動體驗與操作效率。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">22</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20240385440A1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241121</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用安裝於外殼上的顯示器，搭配一塊彎曲的透明覆蓋片，將影像或資訊透過光學方式呈現在使用者眼前，達成抬頭顯示效果。該裝置設有臉部接觸結構，讓使用者可穩固佩戴於頭部，並透過位於外殼內部、朝外配置的感測器擷取環境資料，這些資料經電性傳輸至顯示器後進行影像生成與即時更新。透明覆蓋片不僅保護顯示器，同時具備導光功能，使投影內容與真實場景融合，讓使用者能在不移開視線的情況下接收必要資訊，提升操作便利性與安全性。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US20240385443A1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241121</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過將光學模組安裝於穿戴式電子裝置的外殼內，並搭配可旋轉的外部旋鈕，讓使用者在配戴裝置時，光學感測器能偵測其臉部特徵，顯示器則將影像光束投射至使用者眼睛，以呈現虛擬內容。處理器與光學模組及旋鈕電性連接，可根據旋鈕的旋轉角度或位置，調整顯示內容的沉浸程度，實現互動式抬頭顯示體驗。此設計使使用者能直覺地透過旋鈕操控虛擬影像的呈現效果，提升使用便利性與視覺沉浸感。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>

<!-- 圖層07 -->    
<details>
  <summary id="hud-01" style="margin-left: 30px; cursor: pointer;">     
  抬頭顯示器(HUD) — Apple公司（高引用次數） | 更新日: 2025/5/11     
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">抬頭顯示器(HUD) — Apple公司（高引用次數）</h3>   
  
  <p align="left">
  ✅ 根據統計，Apple 公司目前共擁有 686 件與抬頭顯示器（HUD）相關的專利。其中，2023 年申請的有 146 件（占比 21.3%）、2024 年為 127 件（18.5%）、2020 年為 106 件（15.5%）。截至目前，已有 294 件獲准。<br><br>
  
  ✅ 從國際專利分類（IPC）來看，Apple 的 HUD 專利主要集中於以下三類：<br>
  ▸ <strong>G02B 27/01</strong>（抬頭顯示器，670 計次，占 47.1%）<br>
  ▸ <strong>G06F 3/01</strong>（用於用戶與計算機之間進行互動的輸入裝置或輸出／輸入組合裝置，244 計次，占 17.2%）<br>
  ▸ <strong>G02B 27/00</strong>（其他光學系統或設備，162 計次，占 11.4%）<br><br>

  ✅ 在合作專利分類（CPC）方面，主要分類如下：<br>
  ▸ <strong>G02B 27/0172</strong>（HUD 的特定子類別，778 計次，占 20.7%）<br>
  ▸ <strong>G02B 2027/0138</strong>（具有特定 HUD 結構特徵，448 計次，占 11.9%）<br>
  ▸ <strong>G02B 27/0176</strong>（整合其他光學元件的 HUD，421 計次，占 11.2%）<br><br>

  ✅ 在專利引用次數方面，被引用超過 150 次的專利包括：<br>
  US12126748B2（166 次）、US11258891B2（161 次）、US10306036B2（160 次）、US10897528B2（159 次）、US10530915B2（155 次）、US10686922B2（153 次）。
</p>
  
  
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: left;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">166</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12126748B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241022</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用可調式光學模組，將影像投影至使用者的視野中，使其能在觀看外部環境的同時，同步接收數位資訊。該裝置結合眼鏡式框架、鉸鏈結構與可調整位置的顯示模組，可將影像導引至單眼或雙眼視線前方，達到不需低頭即可閱覽資訊的效果。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">161</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11258891B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220222</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過頭戴式裝置中的顯示器與鄰近鏡片的組合，將由攝影機擷取的環境影像呈現在顯示器上，並根據環境資訊由處理器自動切換顯示模式。當裝置處於內部觀看模式時，顯示器不呈現外部影像；而在偵測到特定外部情境後，會切換至外部觀看模式，於使用者視線前顯示即時環境畫面。此技術可實現在不遮蔽真實視野的前提下，將擴增資訊或即時畫面投影至視野中。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">160</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10306036B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20190528</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過行動電話與頭戴式裝置的結合，當行動電話與頭戴式裝置配對時，其顯示內容會轉換為第二種格式，以適應透過頭戴式顯示器觀看的需求，並將音訊輸出轉為由頭戴裝置內建的喇叭播放。此種運作方式使手機成為HUD系統的一部分，提供視覺與聽覺的延伸輸出，達到在使用者視野中顯示資訊的目的。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">159</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10897528B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20210119</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是利用頭戴式支撐結構承載顯示器與透鏡，將影像呈現在使用者視野中，透過第一與第二透鏡觀看顯示器所輸出的資訊，實現資訊與現實視野的整合。顯示器設置於前面板與透鏡之間，並透過舒適設計如泡棉與頭帶，確保配戴穩定性與使用者舒適度。此裝置具備典型HUD的顯示架構與佩戴方式，可用於虛擬實境或擴增實境應用中，將數位資訊投影至使用者前方視野，達到不轉移注意力即可接收視覺資訊的目的。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">155</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10530915B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20200107</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過頭戴式裝置支撐行動電話，並將其顯示器調整為近距離觀看模式，使使用者可透過第一與第二透鏡觀賞顯示內容。當手機置於對應的停靠區時，會自動切換為適合透過透鏡觀看的顯示格式，提供沉浸式視覺體驗。此系統將行動裝置的顯示功能延伸為HUD顯示用途，讓資訊能夠直接呈現在使用者視線前方，無需手持裝置或轉移注意力。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">153</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US10686922B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20200616</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">本技術之原理是透過一個頭戴式裝置，該裝置包括一個支撐結構、支撐顯示裝置的顯示面板，以及一個光學子組件，使用者透過光學子組件來觀看顯示內容。處理器根據處方資訊調整光學子組件，以便改善顯示內容的視覺效果，特別是對於有視力需求的使用者。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>

<!-- 儀表板01 -->
<details>
  <summary id="dash-01" style="margin-left: 30px; cursor: pointer;">
    【儀表板】Meta專利透視元宇宙技術 | 更新日: 2025/5/4
  </summary>
  <div class="box post" style="width: 80%; margin: 0 auto; line-height: 1.8;">
 
<p align="left">
      ✅ 本儀表板涵蓋截至 <strong>2024/12/31</strong> 前公開、<strong>Meta Platforms公司</strong>的美國專利。<br>
      ✅ 儀表板載入時間約為 1 至 3 分鐘，敬請耐心等候。如網頁閒置過久，請重新整理頁面以恢復儀表板功能。
    </p>
  </div>
  <!-- 內嵌 Dash App iframe -->
  <div class="box post" style="width: 100%; margin: 0 auto;">
    <iframe
      src="https://dash03.onrender.com" style="width: 1660px; height: 812px"> <!-- Dash App 的網址，請替換為你自己的 URL -->
    </iframe>
  </div>
</details>

<!-- 圖層06 + 收合功能 -->   
<details>
  <summary id="meta-06" style="margin-left: 30px; cursor: pointer;">    
  Meta專利透視元宇宙技術 — 渲染技術（高引用次數） | 更新日: 2025/5/8    
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Meta專利透視元宇宙技術 — 渲染技術（高引用次數）</h3>   
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: left;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">216</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11966701B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240423</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種擴增實境裝置中的動態渲染技術，其原理是根據來自裝置上相機的視覺訊號與非視覺感測器（如慣性感測器、生理感測器等）取得的感測訊號，透過層疊式推論過程判斷使用者在真實環境中的情境變化，進而決定是否需要即時調整虛擬物件的渲染方式，並將經調整後的虛擬物件重新渲染至顯示器上，提供符合當前使用者情境的視覺輸出。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">116</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11838258B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231205</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種多通路影像與文字內容渲染技術，其原理是使用者透過編輯介面輸入圖像與文字內容後，系統會依據這些內容同時產生兩種針對不同觀看通路的視覺呈現版本，其中第一種渲染方式會將照片整理成幻燈片，並將文字設置為首張封面卡片；第二種渲染方式則將照片整合為拼貼圖，並將文字加入作為圖片說明，同步也針對文字內容產生適用於不同平台的純文字或加強型文本格式，讓同一份創作內容能根據通路特性呈現出最佳視覺效果。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">53</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12026802B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240702</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種擴增實境特效的預載入渲染技術，其原理是根據過往使用者對特效的使用頻率統計資料，以及各項資源的大小與存取延遲等特性，預測哪些資源在未來可能會被使用並能有效縮短渲染載入時間，進而預先將這些資源存入本地快取中；當系統接收到需套用擴增實境特效的影片訊息後，即可利用這些已快取的資源快速完成影片畫面的渲染，使渲染效能優於即時下載資源的情況，並依照資源排程機制釋放不再需要的快取資源以節省系統資源。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">49</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11967014B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240423</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種三維對話內容的視覺渲染技術，其原理是透過收集包含色彩與深度資訊的三維對話資料，以及相機的校準參數（如拍攝環境條件、相機內部特性與影像雜訊特徵），將這些資料傳送至重建系統，該系統根據校準資料進行多源影像整合與三維輪廓位置推定，生成三維表示模型後，再將其渲染為一張或多張二維影像，供接收端裝置在三維對話情境中呈現即時視覺畫面。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">46</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12020368B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240625</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種基於視覺焦點區域的虛擬場景區域化渲染技術，其原理是先劃分顯示畫面為中央視覺焦點區（foveal region）與外圍區域，並進一步將外圍區域分為兩個子區段，針對這兩個子區段，分別使用不同的像素渲染樣式矩陣，其中每個矩陣元素代表一個像素位置，並區分為需從材質陣列中取樣進行高精度渲染的像素，與可透過像素插值或複製方式快速填補的像素，以此降低周邊視覺區域的運算負擔，同時維持整體畫面品質與渲染效率，最終將計算後的像素值傳送至顯示裝置呈現虛擬畫面。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">45</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11989844B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240521</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種結合虛擬實境與現實物體定位的輪廓渲染技術，其原理是根據使用者頭戴式虛擬實境裝置所擷取的視野與現實環境資訊，首先渲染出含有虛擬邊界的第一張虛擬實境畫面，再透過內建相機判斷現實物體相對於使用者的位置與姿態，並在第二張虛擬畫面中加入這些現實物體的輪廓視圖，且這些輪廓的相對位置會對應真實世界物體的空間姿態，以提供使用者在虛擬場景中也能感知現實物體存在的沉浸式互動體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">45</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11961296B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240416</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種基於體素佔據率的虛擬空間渲染技術，其原理是透過深度感測資料產生周遭實體物件的空間點，再將這些空間點對應至虛擬三維空間中的體素（voxel），計算每個體素的佔據分數，根據這些分數生成與現實空間對應的虛擬場景並顯示給使用者；使用者在該虛擬場景中設定子區域邊界後，系統會持續分析體素分布，若判斷邊界外仍有空閒空間，便提出擴展建議，以增強場景互動性與空間利用效率。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">45</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11721307B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230808</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種針對非線性掃描顯示裝置的時序同步渲染技術，其原理是根據掃描顯示元件的非線性旋轉速度所對應的顯示時序資訊，將整體畫面區分為多個包含完整列的區段，並針對每個區段設定專屬的渲染需求，包括顯示時間間隔與畫面範圍大小，進一步依據不同時間點下使用者的視角位置，對應產生各區段的像素值並分別輸出，使得掃描式顯示器能在不同時刻同步呈現各區段畫面，達到視覺上流暢且時間對齊的顯示效果。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">28</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11917011B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240227</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種基於網路品質調整的增強現實渲染技術，其原理是當接收到顯示多個虛擬物體的渲染請求後，系統根據無線連線的網路品質來調整渲染優先級。若網路品質低於預設閾值，則選擇較高優先級的虛擬物體表面進行優先渲染並傳送至增強現實頭戴裝置顯示，待網路狀況改善後，再傳送較低優先級的表面。這種策略可確保在網路條件不佳時，最重要的渲染內容仍能順利顯示，提升使用者的沉浸體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">28</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11676348B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230613</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種混合現實渲染技術，其原理是利用行動計算裝置的相機擷取虛擬實境顯示裝置所顯示的VR環境畫面，並且根據行動裝置與VR顯示裝置之間的相對姿態，傳送至VR系統來獲取另一視角的VR渲染畫面。接著，系統會將第一位使用者從擷取的影像中分割出來，並即時將這些影像與VR環境的渲染結果進行合成，生成一個混合現實的畫面，將使用者呈現在虛擬環境中，從而實現虛擬與現實元素的融合。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>


<!-- 圖層05 + 收合功能 -->  
<details>
  
  <summary id="meta-05" style="margin-left: 30px; cursor: pointer;">   
  Meta專利透視元宇宙技術 — 機器學習技術（高引用次數） | 更新日: 2025/5/7   
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Meta專利透視元宇宙技術 — 機器學習技術（高引用次數）</h3>  
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: left;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">688</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11715042B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230801</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種用於訓練目標機器學習模型的方法，其原理是透過多次迭代方式，使用包含內容物件的訓練資料來訓練中介模型，該中介模型產生上下文評估指標，進一步產生與訓練資料相關的狀態指標（如使用者意圖、系統行為與使用者行為），再根據這些資訊訓練目標模型。接著，透過序列樣式探勘模型從目標模型中提取規則，以這些規則生成合成訓練資料，並將其加入原始資料集以強化學習過程。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">621</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11688159B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230627</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種根據使用者觸發行為推薦內容的方法，其原理是透過機器學習模型分析使用者啟動的引導內容物件、相關聯的內容物件，以及該使用者的個人資料，來預測並挑選最適合的推薦內容。模型會根據內容之間的語意關聯與使用者過往的偏好模式，判斷出具有高相關性或高吸引力的內容，並將其作為建議項目呈現給使用者。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">363</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11861674B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240102</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種智慧購物輔助方法，其原理是透過用戶端的視覺輸入資料，利用一個或多個機器學習模型進行影像辨識與區域優先處理，以識別使用者視野中的潛在感興趣商品，並進一步結合社群圖譜中其他使用者的社交內容摘要與個人過去的情境記憶，產生個人化的購物建議。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">218</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12125297B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241022</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種從真實世界影像中辨識文字並執行相關任務的方法，其原理是透過機器學習模型對用戶端回傳的影像信號進行文字辨識（如光學文字辨識，OCR），將影像中的文字內容萃取出來後，再根據影像的上下文資訊與知識圖譜中的實體關聯，進行語意理解與任務推論。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">218</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12118790B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20241015</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種根據感測器資料主動捕捉使用者活動相關影像的方法，其原理是透過多種感測器（如加速度計、陀螺儀、麥克風等）收集的訊號，由一組考量成本與相關性的階層式模型政策決定使用哪些感測器資料，再利用機器學習模型分析這些資料以判斷使用者活動中的情境變化，當該變化滿足預設的觸發條件時，自動啟動攝影機捕捉影像。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">176</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11861757B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240102</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種在人工實境環境中呈現使用者自我虛擬形象的方法，其原理是利用安裝於人工實境系統的相機所即時拍攝的影像，透過一個訓練好的機器學習模型辨識影像中的使用者本體部位（如手、手臂、頭部等），並將這些辨識出的身體區塊作為自我表示，依據使用者在虛擬空間中的視角進行定位與顯示。此外，在新影像尚未更新時，系統會根據控制器或已追蹤到的身體部位運動，判斷其位移距離與方向，並對現有的虛擬形象進行動態調整，以提供連貫的視覺回饋。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">111</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11355033B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220607</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種將音訊訊號轉換為觸覺輸出的技術，其原理是將輸入的音訊訊號透過機器學習電路進行編碼，轉化為一系列對應的致動器訊號（haptic cues），以驅動皮膚表面的觸覺回饋裝置。該機器學習電路透過訓練集中的聲音資料進行預處理，包括切分為時間片段並轉換為頻譜圖，進一步以重建誤差與一組約束條件為代價函數進行模型訓練。特定的約束條件設計用以穩定觸覺變化，避免相鄰時間片段間的觸覺輸出出現劇烈變動，從而提供連貫、可感知的觸覺體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">71</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11657094B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230523</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種根據使用者查詢從記憶圖譜中擷取相關資訊以產生回應的方法，其原理是利用機器學習模型解析使用者輸入的查詢與對話上下文，從個人化的記憶圖譜中識別出初始記憶節點，再透過圖遍歷技術（如記憶圖走訪路徑）來推理出與查詢相關的節點序列。這些節點代表使用者過去的情境記憶或經驗，模型會根據圖中的關聯性與語意權重，選出最具代表性的候選節點作為回應依據，最後組合初始記憶與候選記憶內容產生自然語言回應。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">43</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11934445B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240319</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種自動呈現記憶內容項目的方法，其原理是將自然語言（NL）輸入進行區段化處理後，透過機器學習模型來分析每個區段與多個記憶內容項目之間的匹配程度。首先，系統會將每個記憶內容項目與分段後的區塊輸入到機器學習模型中，並針對每個區塊計算子匹配分數。接著，將這些子匹配分數結合起來，生成一個總體的匹配分數，進而選擇出匹配度最高的記憶內容項目。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">43</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11797880B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231024</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種基於機器學習模型自動標示音頻共享區塊的方法，其原理是利用訓練數據集，該數據集包含多個音頻內容片段，這些片段是用戶共享的音頻部分。系統會根據這些數據訓練機器學習模型，讓模型能夠識別輸入音頻內容中符合共享閾值的高亮部分，這些部分的特徵是有明確的開始時間與結束時間指標。當接收到新的音頻內容時，系統會根據訓練好的模型來判斷哪些區域符合共享閾值，並提供對應的指標來標示這些部分。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>


<!-- 圖層04 + 收合功能 --> 
<details>
  
  <summary id="meta-04" style="margin-left: 30px; cursor: pointer;">  
  Meta專利透視元宇宙技術 — 音訊技術（高引用次數） | 更新日: 2025/5/6  
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Meta專利透視元宇宙技術 — 音訊技術（高引用次數）</h3> 
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center; width: 60%;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">140</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12099327B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240924</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種進行全息通話的技術，其原理是透過傳輸同步的視覺與音訊資料來實現擬真通訊體驗。具體來說，系統會在發送端裝置擷取色彩影像、深度影像與音訊資料，經過遮罩與壓縮後一併傳送至接收端，接收端再解壓並將深度影像轉換成3D網格，將色彩影像貼附於該網格上，同時將音訊資料與3D影像同步播放，達成具備語音互動能力的全息影像顯示。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">129</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11991222B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240521</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種在人工實境環境中持續進行語音通話的技術，其原理是透過人工實境裝置整合語音通話功能與使用者介面，使使用者在不同虛擬體驗之間轉換時，仍能持續進行語音通訊。系統透過渲染一個包含語音通話控制選項的覆蓋介面，使使用者能在不同的虛擬場景中控制與其他使用者的語音通話狀態，並根據使用者指令動態調整來自虛擬體驗與語音通話的音訊輸出比例。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">111</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11355033B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220607</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種將音訊訊號轉換為觸覺輸出的技術，其原理是透過機器學習電路將輸入的音訊訊號壓縮並轉換為一連串驅動觸覺回饋裝置的致動訊號。該電路經由訓練資料集中的聲音樣本進行預處理並產生頻譜圖，再以重建誤差與觸覺變化約束為目標函數，進行學習與優化，使模型能將音訊的時序變化準確地對應為觸覺提示序列。最終，這些訊號被輸出至皮膚觸覺致動器，提供使用者與音訊內容同步的觸覺回饋。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">103</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11610593B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230321</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種利用多麥克風進行音訊訊號分離與增強的系統，其原理是透過一組主麥克風與一組環境麥克風接收來自多個聲源的混合音訊，再透過訊號分解器對這些混合訊號進行處理，提取出特定聲源（例如第一聲源）在其發聲起始部分的內在成分。系統利用兩個麥克風之間的距離差異與空間接收特性來幫助識別聲源位置與聲音結構，並藉由處理不同來源訊號的共同成分以提升所需聲源的清晰度與可懂度。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">102</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11416544B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220816</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種根據音訊樣本片段來搜尋與取得音樂作品的技術，其原理是透過分析使用者提供的音訊樣本（例如歌曲片段），運用音訊辨識與相似度比對演算法，判斷該樣本是否為某一音樂作品的片段，或與其他音樂作品具有高度相似性，接著根據比對結果選出對應的音樂作品並從音樂服務平台中抓取該曲目供使用者播放。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">100</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11562744B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230124</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種透過語音風格嵌入進行語音合成回應的技術，其原理是先接收使用者的語音輸入，並根據語音中的韻律特徵、音訊特徵與語音對應的語言標記，生成第一風格嵌入表示，接著根據語音輸入生成相對應的文字回應，再產生該文字回應的第二風格嵌入，最後結合這些風格嵌入與語音特徵，以語音合成模型產生具有相似語氣與風格的語音輸出波形，並透過語音助理應用回傳給使用者。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
<tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">44</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11743628B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230829</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種基於耳朵外耳廓（pinna）振動的音訊系統，其原理是透過一個可連接到耳朵外耳廓的換能器，將音訊指令轉換為使外耳廓振動的能量，進而在耳道入口處產生空氣聲壓波。系統還包含一個聲學感測器，用來監控外耳廓的振動，並將該振動資料反饋給控制器。控制器根據感測器回傳的振動信息，調整音訊指令，從而優化換能器的輸出，實現更加精確的音訊播放。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">44</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11678103B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230613</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種結合組織換能器與空氣傳導換能器的音訊系統，其原理是利用空氣傳導換能器生成空氣聲壓波，這些聲壓波會引起回壓，進而驅動與使用者組織相連的組織換能器振動。組織換能器的振動會使該組織產生聲壓波，這些聲壓波構成音訊內容的一部分，並將其傳遞給使用者。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">43</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11711645B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230725</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種基於環境條件與音漏衰減水平的聲音濾波方法，其原理是透過耳機根據當前環境條件與音頻的音漏衰減水平來決定一個聲音濾波器。這個濾波器會被應用於音訊內容，並透過耳機上的偶極揚聲器播放，從而在指定的音頻頻段中，將音訊內容的音漏衰減至至少達到設計的衰減水平。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">41</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12008700B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240611</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left;">一種音訊系統，其原理是透過一組聲學傳感器陣列來捕捉來自人類聲源的音訊數據，並根據這些音訊數據生成音訊資訊，將其提供給遠端用戶。該系統會根據遠端用戶在虛擬環境中的位置，將音訊資訊與人類聲源的虛擬呈現同步，以便遠端用戶在耳機中聆聽。系統還會預測人類聲源面部表情，並將相應的視覺資訊同步顯示給遠端用戶，使得虛擬環境中的聲音和面部表情協同呈現，提供更加真實的沉浸式體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>

<!-- 圖層03 + 收合功能 --> 
<details>
  
  <summary id="meta-03" style="margin-left: 30px; cursor: pointer;"> 
  Meta專利透視元宇宙技術 — 社交技術（高引用次數） | 更新日: 2025/5/5 
  </summary>
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Meta專利透視元宇宙技術 — 社交技術（高引用次數）</h3>
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center; width: 60%;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">717</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11908179B2</td>
        <td style="border: 1px solid #ccc; text-align: center;">20240220</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種社交推薦技術，其原理是透過線上社群網路分析使用者輸入的主題與意圖，當系統無法以既有的智能代理（agents）處理該意圖時，便會搜尋與該主題相關、且與使用者在社群中有連結的其他實體（如朋友、同事或其他關聯用戶），再根據這些社交連結推薦合適的人選供使用者參考或互動。這樣的設計運用社群關係作為資訊中介，提升問題解決的效率與社交互動的可能性。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">363</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11861674B1</td>
        <td style="border: 1px solid #ccc; text-align: center;">20240102</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種社交導向的產品推薦技術，其原理是透過用戶端裝置所擷取的影像輸入，結合機器學習模型辨識出使用者視野中可能感興趣的產品，並從伺服器端擷取與這些產品相關的社交資料，包括社群網路中與使用者有一定社交關係的其他人所發佈的內容（例如評論、貼文、使用經驗等），進一步產生社交摘要資訊，提供給使用者參考。這些摘要不僅整合他人對該產品的看法，也結合使用者自身過往與產品互動的記憶記錄，用以主動提供個人化的購物建議。透過這種結合社交圖譜與內容摘要的方式，系統能強化社交影響力於消費決策中的作用。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">337</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11888607B2</td>
        <td style="border: 1px solid #ccc; text-align: center;">20240130</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種基於興趣社群的社交媒合技術，其原理是透過社群平台中的探索服務，讓使用者主動註冊參與，並提供希望新連結對象具備的特定屬性（例如興趣、背景或專業領域），系統再從參與該服務、且同為特定興趣社群成員的其他使用者中，篩選出符合這些屬性的人選。當這些候選人的貼文顯示在平台介面上時，系統會透過特定的視覺標示強調其參與探索服務、興趣社群成員身分與符合條件的屬性，以區別於其他未符合條件的使用者貼文，從而促進更具針對性的社交連結與互動。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">333</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11514536B2</td>
        <td style="border: 1px solid #ccc; text-align: center;">20221129</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種結合興趣社群與交友媒合的社交配對技術，其原理是當使用者參與社群平台內建的交友服務時，系統會識別該使用者所屬的各個興趣導向社群，並利用這些社群的資料來篩選出同時參與交友服務且具有相同社群背景的其他使用者。接著，在交友介面中，系統會以圖像方式呈現這些潛在配對對象，並將其與相關的興趣社群視覺上關聯起來，讓使用者能更容易辨識彼此的共同點。這種方式透過興趣導向的社群脈絡強化交友媒合的精準度與互動可能性，促進更有品質的社交關係建立。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">200</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11347388B1</td>
        <td style="border: 1px solid #ccc; text-align: center;">20220531</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種基於社群互動的限時動態內容呈現技術，其原理是社交平台為每個使用者帳號維護一個包含短暫性貼文的個人內容區（user content pod），並為多位使用者所組成的群組維護群組內容區（group content pod），這些貼文會在一定時間後自動失效。系統透過生成封面卡片來視覺化每個內容區，個人區封面以單一貼文圖片為主，而群組區則整合多個貼文的視覺摘要，並將這些封面卡片依特定網格排列於可捲動介面中。透過這種設計，使用者能快速瀏覽並互動於個人或群組動態貼文中，進一步促進平台內的社交互動與內容分享。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">191</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11531678B2</td>
        <td style="border: 1px solid #ccc; text-align: center;">20221220</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種基於社群互動的動態推薦技術，其原理是當使用者在社交網路上發佈一則包含詢問內容的文字貼文後，系統會根據過往其他使用者在類似主題下的回應內容，生成初步的推薦清單，這些推薦來自其他使用者的評論中提及的物件或資訊。之後，系統還會持續追蹤該貼文下新產生的評論，並據此更新推薦清單，使回饋更即時且具社交脈絡。透過彙整社群中的歷史與即時回應，此技術強化了以社交互動為基礎的知識交換與決策支援功能。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">135</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11582182B2</td>
        <td style="border: 1px solid #ccc; text-align: center;">20230214</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種基於使用者互動與內容相似性的社群媒體彙整技術，其原理是系統從多個使用者裝置接收影音片段後，透過媒體特徵分析辨識不同片段之間的內容關聯性，同時考量使用者之間的社交關係，進而將來自不同使用者但相關聯的片段整合為一個共同媒體呈現。此呈現中還包含一段顯示貢獻者名單與片段觀看數據的片段，並提供互動式選項讓觀眾可選擇觀看特定來源的內容。透過結合內容分析與社交網路結構，這項技術鼓勵跨用戶協作與社交互動式的媒體創作與消費。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">118</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11874886B1</td>
        <td style="border: 1px solid #ccc; text-align: center;">20240116</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種簡化社群貼文創作流程的整合式介面技術，其原理是透過在單一畫面中同時提供媒體、文字、中繼資料與張貼欄位，讓使用者無需切換畫面即可完成社群貼文的編輯與發佈。此方式不僅提升使用者體驗與發文效率，也降低發文過程中的流失率，進一步鼓勵在社交平台上的即時內容創作與互動，促進社群活躍度與參與度。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">108</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11775581B1</td>
        <td style="border: 1px solid #ccc; text-align: center;">20231003</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種基於數位社群互動的音樂推薦與分享系統，其原理是透過數位群組訊息中的成員共同選擇音樂並建立共享音樂站，系統根據使用者選擇的初始音樂作品，利用神經網絡分析音樂的特徵並比較群組成員之間的音樂興趣重疊，從中選擇相似且符合成員興趣的額外音樂作品，並將其加入到共享音樂站中。此過程不僅增強了群組成員之間的社交互動，還促進了音樂共享與推薦的社群體驗。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; text-align: center;">108</td>
        <td style="border: 1px solid #ccc; text-align: center;">US11736547B1</td>
        <td style="border: 1px solid #ccc; text-align: center;">20230822</td>
        <td style="border: 1px solid #ccc; text-align: left;">一種結合音樂服務與社交平台的多層次互動體驗系統，其原理是將音樂服務整合為社交平台的主動層與被動層。作為主動層，音樂服務提供專屬的音樂介面，讓使用者能進行音樂消費與分享；而作為被動層，音樂服務則通過即時訊息平台的群組聊天介面，為群組成員創建共享音樂站，讓群組成員能在聊天過程中輕鬆地一起分享與聆聽音樂，進一步強化社群互動及音樂共享的體驗。</td>
        <td style="border: 1px solid #ccc; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>


<!-- 圖層02 + 收合功能 --> 
<details>
  
  <summary id="meta-02" style="margin-left: 30px; cursor: pointer;"> 
  Meta專利透視元宇宙技術 — 視訊技術（高引用次數） | 更新日: 2025/5/3 
  </summary>
  
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Meta專利透視元宇宙技術 — 視訊技術（高引用次數）</h3>
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th> 
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center; width: 60%;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">363</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11861674B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240102</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種利用即時視訊輸入結合人工智慧來辨識使用者感興趣商品的個人化助理系統，其原理是透過用戶端裝置的相機擷取使用者眼前的視野畫面作為視訊輸入，並透過多個機器學習模型分析其中優先區域，以辨識畫面中可能引起使用者注意的商品。系統進一步從雲端伺服器擷取與這些商品相關的社群資料與使用者過往互動內容，進行摘要與推薦生成，最後主動在使用者裝置上呈現個人化的購物建議與社群摘要。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">137</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11711493B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230725</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種結合視訊輸入與人工智慧來進行商品辨識與推薦的互動式助理系統，其原理是透過用戶端裝置的相機擷取使用者視角的即時視訊畫面，並運用機器學習模型對畫面中的特定區域進行優先處理，以辨識使用者可能感興趣的商品。系統再從伺服器端擷取與這些商品相關的社群資料與使用者過往經驗，進一步產出社群摘要與購物建議，並主動在裝置上顯示給使用者。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">105</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11831814B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20231128</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種結合視訊通話與人工實境空間的混合通訊平台，其原理是透過建立一個平行的XR環境，讓配戴頭戴式裝置的使用者能在沉浸式的虛擬空間中同步參與視訊會議，並將視訊通話的畫面切割為多個資料流後，依據預設的虛擬布局安排在XR空間中，同時也將XR使用者的虛擬代表整合進視訊畫面中，讓雙方使用者能跨平台互動與觀看彼此的存在與畫面內容。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">82</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11563997B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230124</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種針對多個使用者所上傳的視訊串流進行即時分析與標註的媒體處理系統，其原理是根據觀看者在社群網路中的屬性，選取與其相關的使用者所產生的視訊內容，並由處理器在視訊畫面中偵測特定物件、辨識對應文字後，將該文字標註於物件旁邊，且在物件移動時持續追蹤並即時更新文字位置。當觀看者切換至另一段視訊串流時，系統也能維持該標註邏輯，使資訊呈現具有連貫性。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">77</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US12100111B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240924</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種在共享XR環境中結合視訊穿透技術與虛擬呈現的互動系統，其原理是透過XR裝置中的攝影機即時擷取現實房間與在地使用者的影像，並將此視訊畫面作為穿透顯示的一部分呈現在虛擬空間中，讓遠端使用者透過虛擬替身觀看當下場景，同時讓在地使用者能在視訊疊加的XR看板上進行互動。系統並根據使用者位置與動作來即時更新虛擬內容，使兩端使用者能在相對應的虛擬與現實空間中同步互動。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">75</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11405676B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220802</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種多來源即時媒體串流整合技術，其原理是從多個使用者裝置接收視訊串流後，根據各串流的視覺特徵與裝置資訊，辨識出拍攝地點與主體相同的兩段串流，並自動從中選擇其中一段的視訊畫面與另一段的音訊內容進行合併，進而動態更新並輸出給觀看者的裝置，使其能觀看畫面清晰或角度較佳的視訊，同時搭配來源更佳的音訊，提升觀看體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">71</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11405347B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20220802</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種遊戲相關內容自動生成與串流技術，其原理是根據使用者預先設定的成就條件，在偵測到該條件於遊戲過程中被達成時，自動擷取並生成包含即時遊戲畫面之視訊串流內容，並將此串流內容加入暫時性內容動態中供其他使用者觀看與互動。此技術亦支援觀眾從視訊中點選加入遊戲，進一步在串流中整合多名玩家的畫面與資訊，實現即時多人互動視訊體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">53</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11736605B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230822</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種協同視訊串流與訊息顯示技術，其原理是透過頭戴式可穿戴設備的攝像頭捕捉視訊數據並進行即時串流，同時腕戴式可穿戴設備接收來自觀眾的電子訊息，並根據頭戴式和腕戴式裝置的傳感器數據（例如位置變化），判斷何時顯示這些訊息。當符合顯示條件時，腕戴裝置會顯示來自觀眾的電子訊息，實現視訊串流與訊息交互的協同操作，提供使用者更加流暢的視訊體驗。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">53</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11632454B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20230418</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種決定何時停止透過頭戴式可穿戴設備捕捉視訊的方法，其原理是透過頭戴式裝置的攝像頭捕捉視訊數據，同時監控與腕戴式設備的連接狀態和位置變化，當頭戴式設備的前方朝向腕戴設備時，根據傳感器數據判斷視訊捕捉的條件已不再符合，進而停止捕捉視頻並將視頻顯示在腕戴設備的螢幕上。這種方法使得視頻捕捉與設備位置的變化緊密結合，提高了捕捉過程的智能化和自動化。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">49</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">US11967014B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">20240423</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種提供三維對話的技術，其原理是透過多個攝影機捕捉顏色與深度資訊，並結合校準資料來進行三維重建。該方法將不同來源的數據融合，並根據校準資料計算位置與輪廓資訊，最終生成3D影像，並將其轉換成2D影像供接收端系統顯示，實現沉浸式的三維視訊對話。這樣的技術可以增強視訊通話的真實感與交互性，特別適用於需要精確呈現空間和人物位置的應用。</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: center;"></td>
      </tr>
    </tbody>
  </table>
</div>
</details>
    
    
    	
    	<!-- 圖層01 + 收合功能 -->
    	<details>
  		
  		<summary id="meta-01" style="margin-left: 30px; cursor: pointer;">
  		Meta專利透視元宇宙技術 — 無線技術（高引用次數） | 更新日: 2025/5/2
  		</summary>
  			
  		
		
<div class="box post" style="width: 80%; margin: 0 auto;">
  <h3 style="text-align: center;">Meta專利透視元宇宙技術 — 無線技術（高引用次數）</h3>
  <table style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">公開/公告日</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">專利號</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center; width: 60%;">描述</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">引用次數</th>
        <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">連結</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20241203</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US12160768B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種無線通訊方法，其原理是透過在授權頻譜（licensed spectrum）與未授權頻譜（unlicensed spectrum）上的無線連線，動態評估並選擇可支援的資料傳輸速率以進行裝置間通訊。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">16</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US12160768B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20240806</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US12058723B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種無線裝置在無線區域網路（WLAN）中進行優先時槽申請與存取的方法，其原理是根據無線節點廣播的支援訊息，無線裝置依照自身流量類型與應用需求，申請特定時槽以優先傳輸延遲敏感的資料。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">24</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US12058723B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20231226</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11852711B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種基於超寬頻（Ultra-Wideband, UWB）無線通訊的干擾管理與資料傳輸方法，其原理是透過檢測干擾情況，動態調整傳輸配置（例如選擇不同的波形格式）以優化無線連線品質。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">29</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11852711B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20231205</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11838369B1</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種無線連結下根據內容類型與通道狀態動態調整存取參數的裝置，其原理是根據無線通道狀況及待傳輸的擴增實境（AR）內容，調整無線連線的存取參數，以優化傳輸效能。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">25</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11838369B1.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20230815</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11729551B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種利用超寬頻（Ultra-Wideband, UWB）無線技術進行裝置定位與音訊呈現的方法，其原理是透過UWB量測確定兩裝置之間的相對方向，並依此方向調整接收來的音訊輸出給使用者。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">24</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11729551B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20230516</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11652550B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種基於視距（Line-Of-Sight, LOS）網路的節點配置與連線方法，其原理是透過節點之間發射窄波束（narrow beam）並進行自動對齊和關聯，建立網路拓撲並進行無線通訊操作。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">57</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11652550B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20230425</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11637916B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種無線通訊系統，其原理是透過無線收發器將加密後的應用資料包傳輸至目的地，其中資料包經過DMA控制器與加密引擎處理，以確保傳輸的安全性和效率。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">18</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11637916B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20230307</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11601532B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種無線通訊系統，其原理是透過兩個微控制器分別管理無線收發器的驅動與應用資料的傳輸，協同完成資料在記憶體與無線裝置間的移動與發送。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">26</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11601532B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20230221</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11588910B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種無線裝置在移動過程中進行邊緣資料服務切換的方法，其原理是透過無線網路將視覺畫面卸載至邊緣設備處理，並根據裝置的預測位置在不同邊緣設備之間進行服務接續，以維持資料傳輸與處理的連續性。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">25</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11588910B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
      <tr>
        <td style="border: 1px solid #ccc; padding: 10px;">20221108</td>
        <td style="border: 1px solid #ccc; padding: 10px;">US11496790B2</td>
        <td style="border: 1px solid #ccc; padding: 10px; text-align: left">一種基於超寬頻（UWB）無線技術的智慧串流裝置控制方法，其原理是透過UWB訊號確定發射裝置的位置，根據該位置選擇性地將控制命令路由至群組中指定的目標裝置。</td>
        <td style="border: 1px solid #ccc; padding: 10px;">20</td>
        <td style="border: 1px solid #ccc; padding: 10px;">
          <a href="meta\meta-US11496790B2.html" target="_blank">詳細內容</a>
        </td>
      </tr>
    </tbody>
  </table>		</div>
		
    	</details>
    	
    </section>

    <!-- 空白區塊 -->
	<div style="height: 500px;"></div>

    <!-- CTA -->
    <section id="cta" class="wrapper style3">
        <h4>©2025 醬找專利 版權所有</h4>
    </section>


</body>
</html>